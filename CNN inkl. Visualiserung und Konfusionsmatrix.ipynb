{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=20,\n",
    "                            zoom_range=0.15,\n",
    "                            width_shift_range=0.2,\n",
    "                            height_shift_range=0.2,\n",
    "                            shear_range=0.15,\n",
    "                            horizontal_flip=True,\n",
    "                            fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATADIR = r'--'\n",
    "\n",
    "CATEGORIES = [\"m\", \"w\",\"z\"] # Intialisierung der Label\n",
    "IMG_SIZE = 100 # Bildgröße\n",
    "\n",
    "for category in CATEGORIES:  \n",
    "    path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
    "    for img in os.listdir(path):  # iterate over each image per dogs and cats\n",
    "        img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "        print(img_array)\n",
    "        plt.imshow(img_array, cmap='gray')  # graph it\n",
    "        plt.show()  # display!\n",
    "\n",
    "        break  # we just want one for now so break\n",
    "    break  #...and one more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trainingsbilder werden mit dem zugehörigen Label in einer Liste gespeichert\n",
    "CATEGORIES = [\"m\", \"w\",\"z\"] # Intialisierung der Label\n",
    "DATADIR = '...' # Ordner in dem die Druckknopfbilder gespeichert sind \n",
    "training_data = []\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:  # Klassen: m, w, z\n",
    "        path = os.path.join(DATADIR,category)  # Erstellung eines path zum Ordner\n",
    "        class_num = CATEGORIES.index(category)  # Klassifikation: 0=m, 1=w, 2=z\n",
    "        for img in tqdm(os.listdir(path)):  # Iteration über alle Bilder im Ordner\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # Konvertierung in array\n",
    "                \n",
    "                training_data.append([img_array, class_num])  # Hinzufügen zu Trainingsdaten\n",
    "            except Exception as e:  \n",
    "                pass    \n",
    "create_training_data()\n",
    "# training_data[0][i]: Druckknopfbild\n",
    "# training_data[1][i]: zugehöriges Label (m, w, z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilen des Datensatzes in Test- und Trainingsdatensatz\n",
    "import random\n",
    "random.shuffle(training_data) # Durchmischen des Datensatzes\n",
    "X = [] # Bilder\n",
    "y = [] # Label\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)    \n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y = to_categorical(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # 80% Trainingsdaten, 20% Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as pickle data\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open pickle data\n",
    "import pickle\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "#X_train = X_train / 255\n",
    "#X_test = X_test /255\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "model = Sequential() # Initialsierung des Modells\n",
    "# Feature Learning aus Faltungsschichten und Max-Pooling Schichten\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(100, 100, 1), activation=\"relu\", padding=\"same\"))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Klassfikation\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "# Initalisieren der Verlustfunktion und des Optimierers\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# Training des Modells\n",
    "history = model.fit(\n",
    "    X_train.reshape(-1, 100, 100, 1),\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=10,\n",
    "validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validierung des neuronalen Netzes in einer Konfusionsmatrix\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "# Speichern der Ergebnisse den Testdatensatzes in einer Liste\n",
    "y_predict = []\n",
    "for i in range(len(X_test)):\n",
    "    y_predict.append(model.predict(X_test[i].reshape(-1,100,100,1))) # Bestimmung des Labels mit dem zuvor trainierten gefalteten neuronalen Netz\n",
    "y_predict = np.array(y_predict).reshape(-1,3)\n",
    "y_predict = y_predict.round() # Liste mit vorhersageten Labels [1, 1, 2, 0, 2, ...] (0=m; 1=w; 2=z)\n",
    "# Formatänderung für die scikit-learn Matrixfunktion\n",
    "y_predict_c = [np.where(r==1)[0][0] for r in y_predict] # vorhergesagte Labe\n",
    "y_test_c = [np.where(r==1)[0][0] for r in y_test] # reale Label\n",
    "# Verwendung der scikit-learn Matrixfunktion\n",
    "matrix = confusion_matrix(y_test_c,y_predict_c) # Konfusionsmatrix\n",
    "\n",
    "\n",
    "\n",
    "### Bestimmung der Konfusionsmatrix der Testergebnisse\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "y_predict = y_predict.round()###\n",
    "\n",
    "\n",
    "\n",
    "cm=confusion_matrix(y_test_c,y_predict_c)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VISUALSIERUNG DER SCHICHTEN\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(32, \n",
    "                  kernel_size=(3, 3), \n",
    "                  activation=\"softmax\", \n",
    "                  input_shape=(100, 100, 1), \n",
    "                  weights=model.layers[0].get_weights()))          \n",
    "\n",
    "result = model2.predict(X_test[16].reshape(1, 100,100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0][:, :, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(result[0][:, :, 0], cmap=\"gray_r\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(X_test[0].reshape(100,100), cmap=\"gray_r\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
